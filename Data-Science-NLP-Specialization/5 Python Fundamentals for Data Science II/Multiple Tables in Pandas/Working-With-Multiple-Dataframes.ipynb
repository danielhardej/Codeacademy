{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working With Multiple Dataframes\n",
    "\n",
    "In order to efficiently store data, we often spread related information across multiple tables. For instance, imagine that we own an e-commerce business and we want to track the products that have been ordered from our website.\n",
    "\n",
    "However, a lot of this information would be repeated. If the same customer makes multiple orders, that customer’s name, address, and phone number will be reported multiple times. If the same product is ordered by multiple customers, then the product price and description will be repeated. This will make our orders table big and unmanageable.\n",
    "\n",
    "So instead, we can split our data into three tables."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inner Merge I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders = pd.read_csv('orders.csv')\n",
    "\n",
    "products = pd.read_csv('products.csv')\n",
    "\n",
    "customers = pd.read_csv('customers.csv')\n",
    "\n",
    "print(orders)\n",
    "print(products)\n",
    "print(customers)\n",
    "\n",
    "order_3_description = \"thing-a-ma-jig\"\n",
    "order_5_phone_number = \"112-358-1321\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inner Merge II\n",
    "\n",
    "It is easy to do this kind of matching for one row, but hard to do it for multiple rows.\n",
    "\n",
    "Luckily, Pandas can efficiently do this for the entire table. We use the `.merge()` method.\n",
    "\n",
    "The `.merge()` method looks for columns that are common between two DataFrames and then looks for rows where those column’s values are the same. It then combines the matching rows into a single row in a new table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sales = pd.read_csv('sales.csv')\n",
    "print(sales)\n",
    "targets = pd.read_csv('targets.csv')\n",
    "print(targets)\n",
    "\n",
    "sales_vs_targets = pd.merge(sales, targets)\n",
    "print(sales_vs_targets)\n",
    "\n",
    "crushing_it = sales_vs_targets[sales_vs_targets.revenue > sales_vs_targets.target]\n",
    "print(crushing_it)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inner Merge III\n",
    "\n",
    "In addition to using `pd.merge()`, each DataFrame has its own `.merge()` method. The `.merge()` method is the same as the `pd.merge()` function, but it is called on one of the DataFrames.\n",
    "\n",
    "We generally use this when we are joining more than two DataFrames together because we can “chain” the commands. For example, the following command would merge orders to customers, and then the resulting DataFrame to products:\n",
    "\n",
    "\n",
    "```python\n",
    "    big_df = orders.merge(customers).merge(products)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sales = pd.read_csv('sales.csv')\n",
    "print(sales)\n",
    "targets = pd.read_csv('targets.csv')\n",
    "print(targets)\n",
    "\n",
    "men_women = pd.read_csv(\"men_women_sales.csv\")\n",
    "\n",
    "all_data = men_women.merge(sales).merge(targets)\n",
    "\n",
    "results = all_data[(all_data.revenue > all_data.target) & (all_data.women>all_data.men)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge on Specific Columns\n",
    "\n",
    "In the previous example, the `.merge()` function “knew” how to combine tables based on the columns that were the same between two tables. For instance, `products` and `orders` both had a column called `product_id`. This won’t always be true when we want to perform a merge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_products = pd.merge(orders, products.rename(columns={'id': 'product_id'}))\n",
    "print(orders_products)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge on Specific Columns II\n",
    "\n",
    "In the previous exercise, we learned how to use `.rename()` to merge two DataFrames whose columns don’t match.\n",
    "\n",
    "If we don’t want to do that, we have another option. We could use the keywords `left_on` and `right_on` to specify which columns we want to perform the merge on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders = pd.read_csv('orders.csv')\n",
    "print(orders)\n",
    "products = pd.read_csv('products.csv')\n",
    "print(products)\n",
    "\n",
    "# Merge orders and products using left_on and right_on\n",
    "orders_products = pd.merge(orders, products, left_on='product_id', right_on='id', suffixes=['_orders', '_products'])\n",
    "print(orders_products)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mismatched Merges\n",
    "\n",
    "In our previous examples, there were always matching values when we were performing our merges. What happens when that isn’t true?\n",
    "\n",
    "Let’s imagine that our products table is out of date and is missing the newest product: Product 5. What happens when someone orders it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders = pd.read_csv('orders.csv')\n",
    "products = pd.read_csv('products.csv')\n",
    "\n",
    "print(orders)\n",
    "print(products)\n",
    "\n",
    "merged_df = pd.merge(orders, products)\n",
    "print(merged_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outer Merge\n",
    "\n",
    "In the previous exercise, we saw that when we merge two DataFrames whose rows don’t match perfectly, we lose the unmatched rows.\n",
    "\n",
    "This type of merge (where we only include matching rows) is called an inner merge. There are other types of merges that we can use when we want to keep information from the unmatched rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_a = pd.read_csv('store_a.csv')\n",
    "print(store_a)\n",
    "store_b = pd.read_csv('store_b.csv')\n",
    "print(store_b)\n",
    "\n",
    "store_a_b_outer = pd.merge(store_a, store_b, how=\"outer\")\n",
    "print(store_a_b_outer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Left Merge\n",
    "\n",
    "Suppose we want to identify which customers are missing phone information. We would want a list of all customers who have email, but don’t have phone.\n",
    "\n",
    "We could get this by performing a Left Merge. A Left Merge includes all rows from the first (left) table, but only rows from the second (right) table that match the first table.\n",
    "\n",
    "For this command, the order of the arguments matters. If the first DataFrame is company_a and we do a left join, we’ll only end up with rows that appear in company_a.\n",
    "\n",
    "By listing company_a first, we get all customers from Company A, and only customers from Company B who are also customers of Company A.\n",
    "\n",
    "## Right Merge\n",
    "\n",
    "Right merge is the exact opposite of left merge. Here, the merged table will include all rows from the second (right) table, but only rows from the first (left) table that match the second table.\n",
    "\n",
    "By listing company_a first and company_b second, we get all customers from Company B, and only customers from Company A who are also customers of Company B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_a = pd.read_csv('store_a.csv')\n",
    "print(store_a)\n",
    "store_b = pd.read_csv('store_b.csv')\n",
    "print(store_b)\n",
    "\n",
    "store_a_b_left = pd.merge(store_a, store_b, how=\"left\")\n",
    "store_b_a_left = pd.merge(store_b, store_a, how=\"left\")\n",
    "\n",
    "print(store_a_b_left)\n",
    "print(store_b_a_left)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenate DataFrames\n",
    "\n",
    "Sometimes, a dataset is broken into multiple tables. For instance, data is often split into multiple CSV files so that each download is smaller.\n",
    "\n",
    "When we need to reconstruct a single DataFrame from multiple smaller DataFrames, we can use the method `pd.concat([df1, df2, df3, ...])`. This method only works if all of the columns are the same in all of the DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "bakery = pd.read_csv('bakery.csv')\n",
    "print(bakery)\n",
    "ice_cream = pd.read_csv('ice_cream.csv')\n",
    "print(ice_cream)\n",
    "\n",
    "menu = pd.concat([bakery, ice_cream])\n",
    "print(menu)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visits = pd.read_csv('visits.csv',\n",
    "                        parse_dates=[1])\n",
    "checkouts = pd.read_csv('checkouts.csv',\n",
    "                        parse_dates=[1])\n",
    "\n",
    "print(visits)\n",
    "print(checkouts)\n",
    "\n",
    "v_to_c = pd.merge(visits, checkouts)\n",
    "v_to_c['time'] = v_to_c.checkout_time - v_to_c.visit_time\n",
    "print(v_to_c['time'].mean())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
